{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B5gtydFXVDaF","executionInfo":{"status":"ok","timestamp":1643310371834,"user_tz":-210,"elapsed":3675,"user":{"displayName":"programmer el","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEEu2U7xuGGdRT1D_UDHmTp6p6SoRvJwRts74l=s64","userId":"06346042105450712556"}},"outputId":"4e8f472e-2ab8-420f-e9ef-16dced8517bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/project6/lit-master/lit-master')"],"metadata":{"id":"H1qS6yapU7hw"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8KcLIa-BUzc4"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","#from matplotlib.mlab import griddata\n","from scipy.interpolate import griddata\n","import tensorflow as tf\n","from neural_network import *\n","from ensembling_methods import *"]},{"cell_type":"markdown","metadata":{"id":"1NvBAkKjUzdC"},"source":["## Define plotting helpers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y5hWSpLXUzdD"},"outputs":[],"source":["def contour(f, lines=None, linewidths=6, alpha=0.9, linestyles='solid', **kw):\n","  set_lims()\n","  grid = np.linspace(-10, 10, 150)\n","  xg, yg = np.meshgrid(grid, grid)\n","  zg = griddata(X[:,0], X[:,1], f, grid, grid, interp='linear')\n","  if lines is not None:\n","    plt.contour(xg, yg, zg, lines, linewidths=linewidths, alpha=alpha, linestyles=linestyles, **kw, vmin=-1, vmax=1)\n","  else:\n","    vlim = np.abs(f).max() * 0.95\n","    plt.contourf(xg, yg, zg, 300, vmin=-vlim, vmax=vlim, **kw)\n","      \n","def scat(x,y,per=2, **kw):\n","  set_lims()\n","  y1 = np.argwhere(y > 0)[:,0]; np.random.shuffle(y1)\n","  y2 = np.argwhere(y <= 0)[:, 0]; np.random.shuffle(y2)\n","  plt.scatter(*x[y1][::per].T, marker='.', c='red', edgecolor=(0,0,0,0.25), s=100, **kw)\n","  plt.scatter(*x[y2][::per].T, marker='.', c='blue', edgecolor=(0,0,0,0.25), s=100, **kw)\n","  \n","def set_lims():\n","  plt.xticks([]); plt.yticks([])\n","  plt.xlim(-10, 10); plt.ylim(-10, 10)"]},{"cell_type":"markdown","metadata":{"id":"x4LzB38zUzdE"},"source":["## Visualize datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OOVdS1i-UzdI"},"outputs":[],"source":["def get_logits(m1,m2):\n","  res = []\n","  with tf.compat.v1.Session() as sess:\n","    m1.init(sess)\n","    m2.init(sess)\n","    res.append(m1.batch_eval(sess, m1.binary_logits,X))\n","    res.append(m2.batch_eval(sess, m2.binary_logits,X))\n","  tf.compat.v1.reset_default_graph()\n","  return res\n","\n","def train_lit(X_,y_,overlap_penalty):\n","  tf.compat.v1.reset_default_graph()\n","  return get_logits(*train_diverse_models(Net,2,X_,y_,lambda_overlap=overlap_penalty,num_epochs=200,learning_rate=0.0001))\n","  \n","def train_rrs(X_,y_):\n","  tf.compat.v1.reset_default_graph()\n","  return get_logits(*train_restart_models(Net,2,X_,y_,num_epochs=200))\n","\n","def train_ncl(X_,y_,overlap_penalty):\n","  tf.compat.v1.reset_default_graph()\n","  return get_logits(*train_neg_corr_models(Net,2,X_,y_,lambda_overlap=overlap_penalty,num_epochs=200,learning_rate=0.0001))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"op4zW8okUzdH"},"outputs":[],"source":["# We'll use a simple 2x256x2 fully connected network\n","class Net(NeuralNetwork):\n","  @property\n","  def x_shape(self): return [None, 24]\n","  @property\n","  def y_shape(self): return [None, 2]\n","  def rebuild_model(self, X, **_):\n","    # We use softplus here because ReLU networks appear to be unable to get high train accuracy\n","    # on the 2xy vs. x^2-y^2 dataset, even trained normally (not in an ensemble)\n","    L0 = X\n","    L1 = tf.compat.v1.layers.dense(L0, 256, name=self.name+'/L1', activation=tf.nn.softplus)\n","    L2 = tf.compat.v1.layers.dense(L1,   2, name=self.name+'/L2', activation=None)\n","    return [L1, L2]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pi3jPSkeUzdK"},"outputs":[],"source":["def train_ncl_with_highest_accurate_penalty(X, y, steps=10, verbose=False):\n","  lower_bound = 1.0\n","  upper_bound = 2.0\n","  best_logits = None\n","  for step in range(steps):\n","    lmb = (lower_bound + upper_bound) / 2.0\n","    m1, m2 = train_neg_corr_models(Net, 2, X, y, lambda_overlap=lmb, num_epochs=100, learning_rate=0.0001)\n","    with tf.compat.v1.Session() as sess:\n","      m1.init(sess)\n","      m2.init(sess)\n","      log1 = m1.batch_eval(sess, m1.binary_logits, X)\n","      log2 = m2.batch_eval(sess, m2.binary_logits, X)\n","    acc1 = np.mean((log1>0)==y)\n","    acc2 = np.mean((log2>0)==y)\n","    if verbose:\n","      print('NCL Î»={}: acc1={:.2f}, acc2={:.2f}'.format(lmb, acc1, acc2))\n","    if acc1 > 0.9 and acc2 > 0.9:\n","      best_logits = get_logits(m1, m2)\n","      lower_bound = lmb\n","    elif acc1 < 0.501 and acc2 < 0.501:\n","      pass # we got unlucky with training, try again\n","    else:\n","      upper_bound = lmb\n","  #assert(best_logits is not None)\n","  return lmb, best_logits"]},{"cell_type":"code","source":["from glob import glob\n","\n","for files in glob('/content/drive/MyDrive/Colab Notebooks/project6/lit-master/lit-master/processed_8/processed_8/*'):\n","    # print(files)\n","    pc = []\n","    sd_pc = []\n","    for items in glob(\"{}/*.*\".format(files)):\n","        print(items)\n","        # print(len(items))\n","\n","        data = np.load(items, allow_pickle=True)\n","        input_list = data.tolist()  # How to get x_train\n","\n","        #print(input_list)\n","        x_train = input_list['FrameStack'][0]\n","        X = x_train\n","        x_test = input_list['FrameStack'][1]\n","        y_train = input_list['FrameStack'][2]\n","        y_test = input_list['FrameStack'][3]\n","        x_val = input_list['FrameStack'][4]\n","        y_val = input_list['FrameStack'][5]\n","        y_shape = max(y_train)+1\n","\n","\n","        # We'll use a simple 2x256x2 fully connected network\n","        class Net(NeuralNetwork):\n","          @property\n","          def x_shape(self): return [None, x_train.shape[1]]\n","          @property\n","          def y_shape(self): return [None, y_shape]\n","          def rebuild_model(self, X, **_):\n","            # We use softplus here because ReLU networks appear to be unable to get high train accuracy\n","            # on the 2xy vs. x^2-y^2 dataset, even trained normally (not in an ensemble)\n","            L0 = X\n","            L1 = tf.compat.v1.layers.dense(L0, 256, name=self.name+'/L1', activation=tf.nn.softplus)\n","            L2 = tf.compat.v1.layers.dense(L1,  y_shape, name=self.name+'/L2', activation=None)\n","            return [L1, L2]\n","        results1 = {}\n","        best_ncl_lambda, best_ncl_logits = train_ncl_with_highest_accurate_penalty(x_train, y_train, verbose=True)\n","        results1['ncl-best'] = best_ncl_logits\n","        results1['ncl-{}'.format(0.1)] = train_ncl(x_train, y_train, 0.1)\n","        results1['restarts'] = train_rrs(x_train, y_train)\n","        for lmb in [0.0001,0.1]:\n","          results1['lit-{}'.format(lmb)] = train_lit(x_train, y_train, lmb)"],"metadata":{"id":"LwFVBwsrQ0Ja"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"2D-Synthetic.ipynb","provenance":[{"file_id":"1tPoqIiV7ykH12_hqz3S4JAQJJaa16sQr","timestamp":1643122232086}],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}